{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests to implement:\n",
    "\n",
    "1. KDD/GDD biases\n",
    "2. LH/SH biases\n",
    "3. Do these biases scale with ag production\n",
    "4. Do these biases change over the growing season\n",
    "5. Do historical cmip6 temperature biases predict future changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import cartopy\n",
    "import cartopy.util\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import sys, os\n",
    "import pickle, gzip\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "run ../util/setupConsole_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirCmip6 = '/home/edcoffel/drive/MAX-Filer/Research/Climate-02/Data-02-edcoffel-F20/CMIP6'\n",
    "dirERA5 = '/home/edcoffel/drive/MAX-Filer/Research/Climate-02/Data-02-edcoffel-F20/ERA5'\n",
    "dirDeepak = '/home/edcoffel/drive/MAX-Filer/Research/Climate-01/Personal-F20/edcoffel-F20/data/projects/ag-land-climate/deepak'\n",
    "dirAgData = '/home/edcoffel/drive/MAX-Filer/Research/Climate-01/Personal-F20/edcoffel-F20/data/projects/ag-land-climate'\n",
    "dirProj = '/home/edcoffel/drive/MAX-Filer/Research/Climate-01/Personal-F20/edcoffel-F20/research/2020-ag-cmip6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('%s/cmip6_output/*.nc'%dirProj)\n",
    "# for f in files:\n",
    "#     os.rename(f,'%s.nc'%f[0:-4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('%s/gdd-kdd-lat-era5.dat'%dirAgData, 'rb') as f:\n",
    "    era5_lat = pickle.load(f)\n",
    "with gzip.open('%s/gdd-kdd-lon-era5.dat'%dirAgData, 'rb') as f:\n",
    "    era5_lon = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip6_models = ['access-cm2', 'access-esm1-5', 'awi-cm-1-1-mr', 'bcc-csm2-mr', 'bcc-esm1', 'canesm5', 'ec-earth3', \\\n",
    "                'gfdl-cm4', 'gfdl-esm4', 'giss-e2-1-g', 'kace-1-0-g', 'fgoals-g3', 'inm-cm5-0', 'ipsl-cm6a-lr', 'miroc6', \\\n",
    "                'mpi-esm1-2-hr', 'mpi-esm1-2-lr', 'mri-esm2-0', 'noresm2-lm', 'noresm2-mm', 'sam0-unicon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'global'\n",
    "\n",
    "if region == 'global':\n",
    "    latRange = [-90, 90]\n",
    "    lonRange = [0, 360]\n",
    "elif region == 'us':\n",
    "    latRange = [20, 57]\n",
    "    lonRange = [220, 300]\n",
    "elif region == 'china':\n",
    "    latRange = [25, 45]\n",
    "    lonRange = [105, 123]\n",
    "elif region == 'eu':\n",
    "    latRange = [38, 56]\n",
    "    lonRange = [-5, 40]\n",
    "\n",
    "latIndRange_era5 = np.where((era5_lat >= latRange[0]) & (era5_lat <= latRange[1]))[0]\n",
    "lonIndRange_era5 = np.where((era5_lon >= lonRange[0]) & (era5_lon <= lonRange[1]))[0]\n",
    "\n",
    "regridMesh_current = xr.Dataset({'lat': (['lat'], np.arange(latRange[0], latRange[1], 1.5)),\n",
    "                            'lon': (['lon'], np.arange(lonRange[0], lonRange[1], 1.5)),})\n",
    "\n",
    "regridMesh_global = xr.Dataset({'lat': (['lat'], np.arange(-90, 90, 1.5)),\n",
    "                                'lon': (['lon'], np.arange(0, 360, 1.5)),})\n",
    "\n",
    "\n",
    "if region == 'global':\n",
    "    regridMesh = regridMesh_global\n",
    "else:\n",
    "    regridMesh = regridMesh_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild = False\n",
    "\n",
    "if rebuild:\n",
    "    for m, model in enumerate(cmip6_models):\n",
    "        print('loading %s'%model)\n",
    "\n",
    "        if os.path.isfile('cmip6_output/cmip6_tasmax_max_%s_regrid_%s.nc'%(region, cmip6_models[m])):\n",
    "            print('skipping %s, exists'%cmip6_models[m])\n",
    "            continue\n",
    "\n",
    "        if not os.path.isfile('cmip6_output/cmip6_tasmax_max_global_%s.nc'%(cmip6_models[m])):\n",
    "            print('skipping %s, base file DOESNT EXIST'%cmip6_models[m])\n",
    "            continue\n",
    "\n",
    "        ds_global_txx = xr.open_dataset('cmip6_output/cmip6_tasmax_max_global_%s.nc'%cmip6_models[m])\n",
    "        ds_global_monthly_txx = xr.open_dataset('cmip6_output/cmip6_tasmax_monthly_max_global_%s.nc'%cmip6_models[m])\n",
    "        ds_global_t50p = xr.open_dataset('cmip6_output/cmip6_tasmax_mean_global_%s.nc'%cmip6_models[m])\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_txx.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_txx.tasmax_max)\n",
    "\n",
    "        da_global_txx_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_txx.time, 'lat':ds_global_txx.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_txx_cyc = xr.Dataset()\n",
    "        ds_global_txx_cyc['tasmax_max'] = da_global_txx_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_txx_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_txx = regridder(ds_global_txx_cyc)\n",
    "\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_monthly_txx.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_monthly_txx.tasmax_monthly_max)\n",
    "\n",
    "        da_global_monthly_txx_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_monthly_txx.time, 'lat':ds_global_monthly_txx.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_monthly_txx_cyc = xr.Dataset()\n",
    "        ds_global_monthly_txx_cyc['tasmax_monthly_max'] = da_global_monthly_txx_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_monthly_txx_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_monthly_txx = regridder(ds_global_monthly_txx_cyc)\n",
    "\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_t50p.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_t50p.tasmax_mean)\n",
    "\n",
    "        da_global_t50p_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_t50p.time, 'lat':ds_global_t50p.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_t50p_cyc = xr.Dataset()\n",
    "        ds_global_t50p_cyc['tasmax_mean'] = da_global_t50p_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_t50p_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_t50p = regridder(ds_global_t50p_cyc)\n",
    "        \n",
    "        cmip6_tasmax_max = ds_global_txx.assign_coords({'model':model})\n",
    "        cmip6_tasmax_monthly_max = ds_global_monthly_txx.assign_coords({'model':model})\n",
    "        cmip6_tasmax_mean = ds_global_t50p.assign_coords({'model':model})\n",
    "\n",
    "        cmip6_tasmax_max.to_netcdf('cmip6_output/cmip6_tasmax_max_regrid_%s_%s.nc'%(region, model))\n",
    "        cmip6_tasmax_monthly_max.to_netcdf('cmip6_output/cmip6_tasmax_monthly_max_regrid_%s_%s.nc'%(region, model))\n",
    "        cmip6_tasmax_mean.to_netcdf('cmip6_output/cmip6_tasmax_mean_regrid_%s_%s.nc'%(region, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = 'Maize'\n",
    "rebuild = False\n",
    "\n",
    "if rebuild:\n",
    "    for m, model in enumerate(cmip6_models):\n",
    "        print('loading %s'%model)\n",
    "\n",
    "#         if os.path.isfile('cmip6_output/growing_season/cmip6_%s_tasmax_grow_max_%s_%s_regrid.nc'%(crop, region, model)):\n",
    "#             print('skipping %s, exists'%cmip6_models[m])\n",
    "#             continue\n",
    "\n",
    "        if not os.path.isfile('cmip6_output/growing_season/cmip6_Maize_grow_tasmax_max_global_%s.nc'%model):\n",
    "            print('skipping %s, base file DOESNT EXIST'%model)\n",
    "            continue\n",
    "\n",
    "        ds_global_tmax = xr.open_dataset('cmip6_output/growing_season/cmip6_Maize_grow_tasmax_max_global_%s.nc'%model)\n",
    "        ds_global_tmean = xr.open_dataset('cmip6_output/growing_season/cmip6_Maize_grow_tasmax_mean_global_%s.nc'%model)\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_tmax.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_tmax.tasmax_grow_max)\n",
    "\n",
    "        da_global_tasmax_grow_tmax_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_tmax.time, 'lat':ds_global_tmax.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        \n",
    "        ds_global_tasmax_grow_tmax_cyc = xr.Dataset()\n",
    "        ds_global_tasmax_grow_tmax_cyc['tasmax_grow_max'] = da_global_tasmax_grow_tmax_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_tasmax_grow_tmax_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_tasmax_grow_tmax_cyc_regrid = regridder(ds_global_tasmax_grow_tmax_cyc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_tmean.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_tmean.tasmax_grow_mean)\n",
    "\n",
    "        da_global_tasmax_grow_tmean_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_tmean.time, 'lat':ds_global_tmean.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        \n",
    "        ds_global_tasmax_grow_tmean_cyc = xr.Dataset()\n",
    "        ds_global_tasmax_grow_tmean_cyc['tasmax_grow_mean'] = da_global_tasmax_grow_tmean_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_tasmax_grow_tmean_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_tasmax_grow_tmean_cyc_regrid = regridder(ds_global_tasmax_grow_tmean_cyc)\n",
    "\n",
    "        ds_global_tasmax_grow_tmax_cyc_regrid = ds_global_tasmax_grow_tmax_cyc_regrid.assign_coords({'model':model})\n",
    "        ds_global_tasmax_grow_tmean_cyc_regrid = ds_global_tasmax_grow_tmean_cyc_regrid.assign_coords({'model':model})\n",
    "\n",
    "        ds_global_tasmax_grow_tmax_cyc_regrid.to_netcdf('cmip6_output/growing_season/cmip6_%s_tasmax_grow_max_%s_%s_regrid.nc'%(crop, region, model))\n",
    "        ds_global_tasmax_grow_tmean_cyc_regrid.to_netcdf('cmip6_output/growing_season/cmip6_%s_tasmax_grow_mean_%s_%s_regrid.nc'%(crop, region, model))\n",
    "        \n",
    "        if os.path.isfile('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_global_%s.nc'%(crop, model)):\n",
    "            print('loading ef for %s'%model)\n",
    "            ds_global_ef = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_global_%s.nc'%(crop, model))\n",
    "            \n",
    "            # add cyclic point before regridding\n",
    "            lon_data = cartopy.util.add_cyclic_point(ds_global_ef.lon)\n",
    "            ef_data = cartopy.util.add_cyclic_point(ds_global_ef.grow_ef)\n",
    "\n",
    "            da_global_ef_grow_cyc = xr.DataArray(data   = ef_data, \n",
    "                              dims   = ['time', 'lat', 'lon'],\n",
    "                              coords = {'time':ds_global_ef.time, 'lat':ds_global_ef.lat, 'lon':lon_data},\n",
    "                              attrs  = {'units'     : 'Fraction'\n",
    "                                })\n",
    "\n",
    "            ds_global_ef_grow_cyc = xr.Dataset()\n",
    "            ds_global_ef_grow_cyc['grow_ef'] = da_global_ef_grow_cyc\n",
    "\n",
    "            regridder = xe.Regridder(ds_global_ef_grow_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "            regridder.clean_weight_file()\n",
    "            ds_global_ef_grow_cyc_regrid = regridder(ds_global_ef_grow_cyc)\n",
    "            \n",
    "            ds_global_ef_grow_cyc_regrid = ds_global_ef_grow_cyc_regrid.assign_coords({'model':model})\n",
    "            ds_global_ef_grow_cyc_regrid.to_netcdf('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_global_%s_regrid.nc'%(crop, model))\n",
    "            \n",
    "        else:\n",
    "            print('skipping ef %s, doesn\\'t exists'%cmip6_models[m])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping ef gfdl-cm4\n",
      "skipping ef gfdl-esm4\n",
      "skipping ef kace-1-0-g\n",
      "skipping ef sam0-unicon\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmax_grow_max = xr.Dataset()\n",
    "cmip6_tasmax_grow_mean = xr.Dataset()\n",
    "cmip6_ef_grow = xr.Dataset()\n",
    "\n",
    "ef_m = 0\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "\n",
    "    if not os.path.isfile('cmip6_output/growing_season/cmip6_%s_tasmax_grow_max_%s_%s_regrid.nc'%(crop, region, model)):\n",
    "        print('skipping tasmax max %s'%model)\n",
    "        \n",
    "        continue\n",
    "    \n",
    "#     print('loading regridded growing season tasmax for %s'%model)\n",
    "\n",
    "    ds_global_txx = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_tasmax_grow_max_%s_%s_regrid.nc'%(crop, region, model))\n",
    "    ds_global_t50p = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_tasmax_grow_mean_%s_%s_regrid.nc'%(crop, region, model))\n",
    "    \n",
    "    if os.path.isfile('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_global_%s_regrid.nc'%(crop, model)):\n",
    "        ds_global_ef = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_global_%s_regrid.nc'%(crop, model))\n",
    "        \n",
    "        if ef_m == 0:\n",
    "            cmip6_ef_grow = ds_global_ef\n",
    "        else:\n",
    "            cmip6_ef_grow = xr.concat([cmip6_ef_grow, ds_global_ef], dim='model')\n",
    "        ef_m += 1\n",
    "    else:\n",
    "        print('skipping ef %s'%model)\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmax_grow_max = ds_global_txx\n",
    "        cmip6_tasmax_grow_mean = ds_global_t50p\n",
    "    else:\n",
    "        cmip6_tasmax_grow_max = xr.concat([cmip6_tasmax_grow_max, ds_global_txx], dim='model')\n",
    "        cmip6_tasmax_grow_mean = xr.concat([cmip6_tasmax_grow_mean, ds_global_t50p], dim='model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading regridded tasmax for access-cm2\n",
      "loading regridded tasmax for access-esm1-5\n",
      "loading regridded tasmax for awi-cm-1-1-mr\n",
      "loading regridded tasmax for bcc-csm2-mr\n",
      "loading regridded tasmax for bcc-esm1\n",
      "loading regridded tasmax for canesm5\n",
      "loading regridded tasmax for ec-earth3\n",
      "loading regridded tasmax for gfdl-cm4\n",
      "loading regridded tasmax for gfdl-esm4\n",
      "loading regridded tasmax for giss-e2-1-g\n",
      "loading regridded tasmax for kace-1-0-g\n",
      "loading regridded tasmax for fgoals-g3\n",
      "loading regridded tasmax for inm-cm5-0\n",
      "loading regridded tasmax for ipsl-cm6a-lr\n",
      "loading regridded tasmax for miroc6\n",
      "loading regridded tasmax for mpi-esm1-2-hr\n",
      "loading regridded tasmax for mpi-esm1-2-lr\n",
      "loading regridded tasmax for mri-esm2-0\n",
      "loading regridded tasmax for noresm2-lm\n",
      "loading regridded tasmax for noresm2-mm\n",
      "loading regridded tasmax for sam0-unicon\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmax_max = xr.Dataset()\n",
    "cmip6_tasmax_monthly_max = xr.Dataset()\n",
    "cmip6_tasmax_mean = xr.Dataset()\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "\n",
    "    print('loading regridded tasmax for %s'%model)\n",
    "\n",
    "    ds_global_txx = xr.open_dataset('cmip6_output/cmip6_tasmax_max_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_monthly_tx = xr.open_dataset('cmip6_output/cmip6_tasmax_monthly_max_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_t50p = xr.open_dataset('cmip6_output/cmip6_tasmax_mean_regrid_%s_%s.nc'%(region, model))\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmax_max = ds_global_txx\n",
    "        cmip6_tasmax_monthly_max = ds_global_monthly_tx\n",
    "        cmip6_tasmax_mean = ds_global_t50p\n",
    "    else:\n",
    "        cmip6_tasmax_max = xr.concat([cmip6_tasmax_max, ds_global_txx], dim='model')\n",
    "        cmip6_tasmax_monthly_max = xr.concat([cmip6_tasmax_monthly_max, ds_global_monthly_tx], dim='model')\n",
    "        cmip6_tasmax_mean = xr.concat([cmip6_tasmax_mean, ds_global_t50p], dim='model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild = False\n",
    "\n",
    "\n",
    "if rebuild:\n",
    "    for m, model in enumerate(cmip6_models):\n",
    "        print('loading %s'%model)\n",
    "\n",
    "        if os.path.isfile('cmip6_output/cmip6_tasmin_max_%s_regrid_%s.nc'%(region, model)):\n",
    "            print('skipping %s, exists'%cmip6_models[m])\n",
    "            continue\n",
    "\n",
    "        if not os.path.isfile('cmip6_output/cmip6_tasmin_max_global_%s.nc'%(model)):\n",
    "            print('skipping %s, base file DOESNT EXIST'%cmip6_models[m])\n",
    "            continue\n",
    "\n",
    "        ds_global_txx = xr.open_dataset('cmip6_output/cmip6_tasmin_max_global_%s.nc'%model)\n",
    "        ds_global_monthly_txx = xr.open_dataset('cmip6_output/cmip6_tasmin_monthly_max_global_%s.nc'%model)\n",
    "        ds_global_t50p = xr.open_dataset('cmip6_output/cmip6_tasmin_mean_global_%s.nc'%model)\n",
    "\n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_txx.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_txx.tasmin_max)\n",
    "\n",
    "        da_global_txx_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_txx.time, 'lat':ds_global_txx.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_txx_cyc = xr.Dataset()\n",
    "        ds_global_txx_cyc['tasmin_max'] = da_global_txx_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_txx_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_txx = regridder(ds_global_txx_cyc)\n",
    "\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_monthly_txx.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_monthly_txx.tasmin_monthly_max)\n",
    "\n",
    "        da_global_monthly_txx_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_monthly_txx.time, 'lat':ds_global_monthly_txx.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_monthly_txx_cyc = xr.Dataset()\n",
    "        ds_global_monthly_txx_cyc['tasmin_monthly_max'] = da_global_monthly_txx_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_monthly_txx_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_monthly_txx = regridder(ds_global_monthly_txx_cyc)\n",
    "\n",
    "        \n",
    "        # add cyclic point before regridding\n",
    "        lon_data = cartopy.util.add_cyclic_point(ds_global_t50p.lon)\n",
    "        temp_data = cartopy.util.add_cyclic_point(ds_global_t50p.tasmin_mean)\n",
    "\n",
    "        da_global_t50p_cyc = xr.DataArray(data   = temp_data, \n",
    "                          dims   = ['time', 'lat', 'lon'],\n",
    "                          coords = {'time':ds_global_t50p.time, 'lat':ds_global_t50p.lat, 'lon':lon_data},\n",
    "                          attrs  = {'units'     : 'C'\n",
    "                            })\n",
    "        ds_global_t50p_cyc = xr.Dataset()\n",
    "        ds_global_t50p_cyc['tasmin_mean'] = da_global_t50p_cyc\n",
    "        \n",
    "        regridder = xe.Regridder(ds_global_t50p_cyc, regridMesh, 'bilinear', reuse_weights=True)\n",
    "        regridder.clean_weight_file()\n",
    "        ds_global_t50p = regridder(ds_global_t50p_cyc)\n",
    "\n",
    "        cmip6_tasmin_max = ds_global_txx.assign_coords({'model':model})\n",
    "        cmip6_tasmin_monthly_max = ds_global_monthly_txx.assign_coords({'model':model})\n",
    "        cmip6_tasmin_mean = ds_global_t50p.assign_coords({'model':model})\n",
    "\n",
    "        cmip6_tasmin_max.to_netcdf('cmip6_output/cmip6_tasmin_max_regrid_%s_%s.nc'%(region, model))\n",
    "        cmip6_tasmin_monthly_max.to_netcdf('cmip6_output/cmip6_tasmin_monthly_max_regrid_%s_%s.nc'%(region, model))\n",
    "        cmip6_tasmin_mean.to_netcdf('cmip6_output/cmip6_tasmin_mean_regrid_%s_%s.nc'%(region, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading regridded tasmin for access-cm2\n",
      "loading regridded tasmin for access-esm1-5\n",
      "loading regridded tasmin for awi-cm-1-1-mr\n",
      "skipping bcc-csm2-mr, base file DOESNT EXIST\n",
      "loading regridded tasmin for bcc-esm1\n",
      "loading regridded tasmin for canesm5\n",
      "loading regridded tasmin for ec-earth3\n",
      "skipping gfdl-cm4, base file DOESNT EXIST\n",
      "skipping gfdl-esm4, base file DOESNT EXIST\n",
      "loading regridded tasmin for giss-e2-1-g\n",
      "skipping kace-1-0-g, base file DOESNT EXIST\n",
      "loading regridded tasmin for fgoals-g3\n",
      "loading regridded tasmin for inm-cm5-0\n",
      "loading regridded tasmin for ipsl-cm6a-lr\n",
      "loading regridded tasmin for miroc6\n",
      "loading regridded tasmin for mpi-esm1-2-hr\n",
      "loading regridded tasmin for mpi-esm1-2-lr\n",
      "loading regridded tasmin for mri-esm2-0\n",
      "loading regridded tasmin for noresm2-lm\n",
      "loading regridded tasmin for noresm2-mm\n",
      "skipping sam0-unicon, base file DOESNT EXIST\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmin_max = xr.Dataset()\n",
    "cmip6_tasmin_monthly_max = xr.Dataset()\n",
    "cmip6_tasmin_mean = xr.Dataset()\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "    \n",
    "    if not os.path.isfile('cmip6_output/cmip6_tasmin_max_regrid_%s_%s.nc'%(region, model)):\n",
    "        print('skipping %s, base file DOESNT EXIST'%model)\n",
    "        continue\n",
    "    \n",
    "    print('loading regridded tasmin for %s'%model)\n",
    "\n",
    "    ds_global_txx = xr.open_dataset('cmip6_output/cmip6_tasmin_max_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_monthly_tx = xr.open_dataset('cmip6_output/cmip6_tasmin_monthly_max_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_t50p = xr.open_dataset('cmip6_output/cmip6_tasmin_mean_regrid_%s_%s.nc'%(region, model))\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmin_max = ds_global_txx\n",
    "        cmip6_tasmin_monthly_max = ds_global_monthly_tx\n",
    "        cmip6_tasmin_mean = ds_global_t50p\n",
    "    else:\n",
    "        cmip6_tasmin_max = xr.concat([cmip6_tasmin_max, ds_global_txx], dim='model')\n",
    "        cmip6_tasmin_monthly_max = xr.concat([cmip6_tasmin_monthly_max, ds_global_monthly_tx], dim='model')\n",
    "        cmip6_tasmin_mean = xr.concat([cmip6_tasmin_mean, ds_global_t50p], dim='model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trends for access-cm2\n",
      "loading trends for access-esm1-5\n",
      "loading trends for awi-cm-1-1-mr\n",
      "loading trends for bcc-csm2-mr\n",
      "loading trends for bcc-esm1\n",
      "loading trends for canesm5\n",
      "loading trends for ec-earth3\n",
      "loading trends for gfdl-cm4\n",
      "loading trends for gfdl-esm4\n",
      "loading trends for giss-e2-1-g\n",
      "loading trends for kace-1-0-g\n",
      "loading trends for fgoals-g3\n",
      "loading trends for inm-cm5-0\n",
      "loading trends for ipsl-cm6a-lr\n",
      "loading trends for miroc6\n",
      "loading trends for mpi-esm1-2-hr\n",
      "loading trends for mpi-esm1-2-lr\n",
      "loading trends for mri-esm2-0\n",
      "loading trends for noresm2-lm\n",
      "loading trends for noresm2-mm\n",
      "loading trends for sam0-unicon\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmax_max_trend = xr.Dataset()\n",
    "cmip6_tasmax_monthly_max_trend = xr.Dataset()\n",
    "cmip6_tasmax_mean_trend = xr.Dataset()\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "\n",
    "    if not os.path.isfile('cmip6_output/cmip6_tasmax_max_trend_regrid_%s_%s.nc'%(region, model)):\n",
    "        print('skipping %s, base file DOESNT EXIST'%model)\n",
    "        continue\n",
    "    \n",
    "    print('loading trends for %s'%model)\n",
    "\n",
    "    ds_global_txx_trend = xr.open_dataset('cmip6_output/cmip6_tasmax_max_trend_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_monthly_tx_trend = xr.open_dataset('cmip6_output/cmip6_tasmax_monthly_max_trend_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_t50p_trend = xr.open_dataset('cmip6_output/cmip6_tasmax_mean_trend_regrid_%s_%s.nc'%(region, model))\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmax_max_trend = ds_global_txx_trend\n",
    "        cmip6_tasmax_monthly_max_trend = ds_global_monthly_tx_trend\n",
    "        cmip6_tasmax_mean_trend = ds_global_t50p_trend\n",
    "    else:\n",
    "        cmip6_tasmax_max_trend = xr.concat([cmip6_tasmax_max_trend, ds_global_txx_trend], dim='model')\n",
    "        cmip6_tasmax_monthly_max_trend = xr.concat([cmip6_tasmax_monthly_max_trend, ds_global_monthly_tx_trend], dim='model')\n",
    "        cmip6_tasmax_mean_trend = xr.concat([cmip6_tasmax_mean_trend, ds_global_t50p_trend], dim='model')\n",
    "\n",
    "# cmip6_tasmax_max_trend = cmip6_tasmax_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmax_monthly_max_trend = cmip6_tasmax_monthly_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmax_mean_trend = cmip6_tasmax_mean_trend.assign_coords({'model':cmip6_models})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading growing season trends for access-cm2\n",
      "loading growing season trends for access-esm1-5\n",
      "loading growing season trends for awi-cm-1-1-mr\n",
      "loading growing season trends for bcc-csm2-mr\n",
      "loading growing season trends for bcc-esm1\n",
      "loading growing season trends for canesm5\n",
      "loading growing season trends for ec-earth3\n",
      "loading growing season trends for gfdl-cm4\n",
      "skipping ef gfdl-cm4\n",
      "loading growing season trends for gfdl-esm4\n",
      "skipping ef gfdl-esm4\n",
      "loading growing season trends for giss-e2-1-g\n",
      "loading growing season trends for kace-1-0-g\n",
      "skipping ef kace-1-0-g\n",
      "loading growing season trends for fgoals-g3\n",
      "loading growing season trends for inm-cm5-0\n",
      "loading growing season trends for ipsl-cm6a-lr\n",
      "loading growing season trends for miroc6\n",
      "loading growing season trends for mpi-esm1-2-hr\n",
      "loading growing season trends for mpi-esm1-2-lr\n",
      "loading growing season trends for mri-esm2-0\n",
      "loading growing season trends for noresm2-lm\n",
      "loading growing season trends for noresm2-mm\n",
      "loading growing season trends for sam0-unicon\n",
      "skipping ef sam0-unicon\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmax_grow_max_trend = xr.Dataset()\n",
    "cmip6_tasmax_grow_mean_trend = xr.Dataset()\n",
    "cmip6_ef_grow_trend = xr.Dataset()\n",
    "\n",
    "ef_m = 0\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "\n",
    "    if not os.path.isfile('cmip6_output/growing_season/cmip6_%s_%s_grow_max_trend_%s_%s_regrid.nc'%(crop, 'tasmax', region, model)):\n",
    "        print('skipping %s, base file DOESNT EXIST'%model)\n",
    "        continue\n",
    "    \n",
    "    print('loading growing season trends for %s'%model)\n",
    "\n",
    "    if os.path.isfile('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_trend_global_%s_regrid.nc'%(crop, model)):\n",
    "        ds_global_ef_trend = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_grow_ef_mon_trend_global_%s_regrid.nc'%(crop, model))\n",
    "        \n",
    "        if ef_m == 0:\n",
    "            cmip6_ef_grow_trend = ds_global_ef_trend\n",
    "        else:\n",
    "            cmip6_ef_grow_trend = xr.concat([cmip6_ef_grow_trend, ds_global_ef_trend], dim='model')\n",
    "        ef_m += 1\n",
    "    else:\n",
    "        print('skipping ef %s'%model)\n",
    "    \n",
    "    ds_global_txx_trend = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_%s_grow_max_trend_%s_%s_regrid.nc'%(crop, 'tasmax', region, model))\n",
    "    ds_global_t50p_trend = xr.open_dataset('cmip6_output/growing_season/cmip6_%s_%s_grow_mean_trend_%s_%s_regrid.nc'%(crop, 'tasmax', region, model))\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmax_grow_max_trend = ds_global_txx_trend\n",
    "        cmip6_tasmax_grow_mean_trend = ds_global_t50p_trend\n",
    "    else:\n",
    "        cmip6_tasmax_grow_max_trend = xr.concat([cmip6_tasmax_grow_max_trend, ds_global_txx_trend], dim='model')\n",
    "        cmip6_tasmax_grow_mean_trend = xr.concat([cmip6_tasmax_grow_mean_trend, ds_global_t50p_trend], dim='model')\n",
    "\n",
    "# cmip6_tasmax_max_trend = cmip6_tasmax_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmax_monthly_max_trend = cmip6_tasmax_monthly_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmax_mean_trend = cmip6_tasmax_mean_trend.assign_coords({'model':cmip6_models})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trends for access-cm2\n",
      "loading trends for access-esm1-5\n",
      "loading trends for awi-cm-1-1-mr\n",
      "skipping bcc-csm2-mr, base file DOESNT EXIST\n",
      "loading trends for bcc-esm1\n",
      "loading trends for canesm5\n",
      "loading trends for ec-earth3\n",
      "skipping gfdl-cm4, base file DOESNT EXIST\n",
      "skipping gfdl-esm4, base file DOESNT EXIST\n",
      "loading trends for giss-e2-1-g\n",
      "skipping kace-1-0-g, base file DOESNT EXIST\n",
      "loading trends for fgoals-g3\n",
      "loading trends for inm-cm5-0\n",
      "loading trends for ipsl-cm6a-lr\n",
      "loading trends for miroc6\n",
      "loading trends for mpi-esm1-2-hr\n",
      "loading trends for mpi-esm1-2-lr\n",
      "loading trends for mri-esm2-0\n",
      "loading trends for noresm2-lm\n",
      "loading trends for noresm2-mm\n",
      "skipping sam0-unicon, base file DOESNT EXIST\n"
     ]
    }
   ],
   "source": [
    "cmip6_tasmin_max_trend = xr.Dataset()\n",
    "cmip6_tasmin_monthly_max_trend = xr.Dataset()\n",
    "cmip6_tasmin_mean_trend = xr.Dataset()\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "\n",
    "    if not os.path.isfile('cmip6_output/cmip6_tasmin_max_trend_regrid_%s_%s.nc'%(region, model)):\n",
    "        print('skipping %s, base file DOESNT EXIST'%model)\n",
    "        continue\n",
    "    \n",
    "    print('loading trends for %s'%model)\n",
    "\n",
    "    ds_global_txx_trend = xr.open_dataset('cmip6_output/cmip6_tasmin_max_trend_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_monthly_tx_trend = xr.open_dataset('cmip6_output/cmip6_tasmin_monthly_max_trend_regrid_%s_%s.nc'%(region, model))\n",
    "    ds_global_t50p_trend = xr.open_dataset('cmip6_output/cmip6_tasmin_mean_trend_regrid_%s_%s.nc'%(region, model))\n",
    "\n",
    "    if m == 0:\n",
    "        cmip6_tasmin_max_trend = ds_global_txx_trend\n",
    "        cmip6_tasmin_monthly_max_trend = ds_global_monthly_tx_trend\n",
    "        cmip6_tasmin_mean_trend = ds_global_t50p_trend\n",
    "    else:\n",
    "        cmip6_tasmin_max_trend = xr.concat([cmip6_tasmin_max_trend, ds_global_txx_trend], dim='model')\n",
    "        cmip6_tasmin_monthly_max_trend = xr.concat([cmip6_tasmin_monthly_max_trend, ds_global_monthly_tx_trend], dim='model')\n",
    "        cmip6_tasmin_mean_trend = xr.concat([cmip6_tasmin_mean_trend, ds_global_t50p_trend], dim='model')\n",
    "\n",
    "# cmip6_tasmin_max_trend = cmip6_tasmin_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmin_monthly_max_trend = cmip6_tasmin_monthly_max_trend.assign_coords({'model':cmip6_models})\n",
    "# cmip6_tasmin_mean_trend = cmip6_tasmin_mean_trend.assign_coords({'model':cmip6_models})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre-computed era5...\n",
      "CPU times: user 16.2 ms, sys: 90 Âµs, total: 16.2 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile('era5/era5_tasmax_max_regrid_%s.nc'%region):\n",
    "    print('loading pre-computed era5...')\n",
    "    era5_tasmax_max_regrid = xr.open_dataset('era5/era5_tasmax_max_regrid_%s.nc'%region)\n",
    "else:\n",
    "    era5_tasmax_max = xr.open_dataset('era5/era5_tasmax_max_global.nc')\n",
    "    era5_tasmax_max = era5_tasmax_max.sel(time=slice('1981', '2014'))\n",
    "\n",
    "    regridder = xe.Regridder(era5_tasmax_max, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_tasmax_max_regrid = regridder(era5_tasmax_max)\n",
    "    era5_tasmax_max_regrid.to_netcdf('era5/era5_tasmax_max_regrid_%s.nc'%region)\n",
    "\n",
    "if os.path.isfile('era5/era5_tasmax_monthly_max_regrid_%s.nc'%region):\n",
    "    era5_tasmax_monthly_max_regrid = xr.open_dataset('era5/era5_tasmax_monthly_max_regrid_%s.nc'%region)\n",
    "else:\n",
    "    era5_tasmax_monthly_max = xr.open_dataset('era5/era5_tasmax_monthly_max_global.nc')\n",
    "    era5_tasmax_monthly_max = era5_tasmax_monthly_max.sel(time=slice('1981', '2014'))\n",
    "\n",
    "    regridder = xe.Regridder(era5_tasmax_monthly_max, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_tasmax_monthly_max_regrid = regridder(era5_tasmax_monthly_max)\n",
    "    era5_tasmax_monthly_max_regrid.to_netcdf('era5/era5_tasmax_monthly_max_regrid_%s.nc'%region)\n",
    "\n",
    "if os.path.isfile('era5/era5_tasmax_mean_regrid_%s.nc'%region):\n",
    "    era5_tasmax_mean_regrid = xr.open_dataset('era5/era5_tasmax_mean_regrid_%s.nc'%region)\n",
    "else:\n",
    "    era5_tasmax_mean = xr.open_dataset('era5/era5_tasmax_mean_global.nc')\n",
    "    era5_tasmax_mean = era5_tasmax_mean.sel(time=slice('1981', '2014'))\n",
    "\n",
    "    regridder = xe.Regridder(era5_tasmax_mean, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_tasmax_mean_regrid = regridder(era5_tasmax_mean)\n",
    "    era5_tasmax_mean_regrid.to_netcdf('era5/era5_tasmax_mean_regrid_%s.nc'%region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load era5 growing season temps\n",
    "\n",
    "rebuild = False\n",
    "\n",
    "if rebuild or not os.path.isfile('era5/growing_season/era5_%s_tasmax_grow_max_regrid_%s.nc'%(crop,region)):\n",
    "\n",
    "    era5_tasmax_grow_max = xr.Dataset()\n",
    "    era5_tasmax_grow_mean = xr.Dataset()\n",
    "\n",
    "    era5_ef_grow = xr.Dataset()\n",
    "    \n",
    "    for y, year in enumerate(range(1981, 2014+1)):\n",
    "\n",
    "        print('loading era5 growing season for %d'%year)\n",
    "\n",
    "        ds_global_txx = xr.open_dataset('era5/growing_season/era5_%s_tasmax_grow_max_global_%s.nc'%(crop, year))\n",
    "        ds_global_t50p = xr.open_dataset('era5/growing_season/era5_%s_tasmax_grow_mean_global_%s.nc'%(crop, year))\n",
    "\n",
    "        ds_global_ef = xr.open_dataset('era5/growing_season/era5_%s_ef_grow_global_%s.nc'%(crop, year))\n",
    "        \n",
    "        if y == 0:\n",
    "            era5_tasmax_grow_max = ds_global_txx\n",
    "            era5_tasmax_grow_mean = ds_global_t50p\n",
    "            \n",
    "            era5_ef_grow = ds_global_ef\n",
    "        else:\n",
    "            era5_tasmax_grow_max = xr.concat([era5_tasmax_grow_max, ds_global_txx], dim='time')\n",
    "            era5_tasmax_grow_mean = xr.concat([era5_tasmax_grow_mean, ds_global_t50p], dim='time')\n",
    "            \n",
    "            era5_ef_grow = xr.concat([era5_ef_grow, ds_global_ef], dim='time')\n",
    "\n",
    "    regridder = xe.Regridder(era5_tasmax_grow_max, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_tasmax_grow_max_regrid = regridder(era5_tasmax_grow_max)\n",
    "    era5_tasmax_grow_max_regrid.to_netcdf('era5/growing_season/era5_%s_tasmax_grow_max_regrid_%s.nc'%(crop,region))\n",
    "\n",
    "    regridder = xe.Regridder(era5_tasmax_grow_mean, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_tasmax_grow_mean_regrid = regridder(era5_tasmax_grow_mean)\n",
    "    era5_tasmax_grow_mean_regrid.to_netcdf('era5/growing_season/era5_%s_tasmax_grow_mean_regrid_%s.nc'%(crop,region))\n",
    "    \n",
    "    regridder = xe.Regridder(era5_ef_grow, regridMesh, 'bilinear', reuse_weights=True)\n",
    "    regridder.clean_weight_file()\n",
    "    era5_ef_grow_regrid = regridder(era5_ef_grow)\n",
    "    era5_ef_grow_regrid.to_netcdf('era5/growing_season/era5_%s_ef_grow_regrid_%s.nc'%(crop,region))\n",
    "else:\n",
    "    era5_tasmax_grow_max_regrid = xr.open_dataset('era5/growing_season/era5_%s_tasmax_grow_max_regrid_%s.nc'%(crop,region))\n",
    "    era5_tasmax_grow_mean_regrid = xr.open_dataset('era5/growing_season/era5_%s_tasmax_grow_mean_regrid_%s.nc'%(crop,region))\n",
    "    era5_ef_grow_regrid = xr.open_dataset('era5/growing_season/era5_%s_ef_grow_regrid_%s.nc'%(crop,region))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 ms, sys: 0 ns, total: 15.5 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recalc = False\n",
    "\n",
    "# era5 trends for growing season data\n",
    "\n",
    "if recalc:\n",
    "\n",
    "    # calc era5 txx and t50p trends\n",
    "    era5_tasmax_grow_max_trend = xr.Dataset()\n",
    "    era5_tasmax_grow_mean_trend = xr.Dataset()\n",
    "    era5_ef_grow_trend = xr.Dataset()\n",
    "\n",
    "    print('calc era5 txx, t50p, and ef trends')\n",
    "    tmp_tasmax_grow_max_trend = np.full([era5_tasmax_grow_max_regrid.lat.values.shape[0], era5_tasmax_grow_max_regrid.lon.values.shape[0]], np.nan)\n",
    "    tmp_tasmax_grow_mean_trend = np.full([era5_tasmax_grow_mean_regrid.lat.values.shape[0], era5_tasmax_grow_mean_regrid.lon.values.shape[0]], np.nan)\n",
    "    tmp_ef_grow_trend = np.full([era5_ef_grow_regrid.lat.values.shape[0], era5_ef_grow_regrid.lon.values.shape[0]], np.nan)\n",
    "\n",
    "    for xlat in range(tmp_tasmax_grow_max_trend.shape[0]):\n",
    "        for ylon in range(tmp_tasmax_grow_max_trend.shape[1]):\n",
    "            cur_tasmax_grow_max = era5_tasmax_grow_max_regrid.tasmax_grow_max.values[:, xlat, ylon]\n",
    "            X = sm.add_constant(range(1981, 2014+1))\n",
    "            mdl = sm.OLS(cur_tasmax_grow_max, X).fit()\n",
    "            tmp_tasmax_grow_max_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "            cur_tasmax_grow_mean = era5_tasmax_grow_mean_regrid.tasmax_grow_mean.values[:, xlat, ylon]\n",
    "            X = sm.add_constant(range(1981, 2014+1))\n",
    "            mdl = sm.OLS(cur_tasmax_grow_mean, X).fit()\n",
    "            tmp_tasmax_grow_mean_trend[xlat, ylon] = mdl.params[1]*10\n",
    "            \n",
    "            cur_ef_grow = era5_ef_grow_regrid.ef_grow.values[:, xlat, ylon]\n",
    "            X = sm.add_constant(range(1981, 2014+1))\n",
    "            mdl = sm.OLS(cur_ef_grow, X).fit()\n",
    "            tmp_ef_grow_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "    era5_tasmax_grow_max_trend['tasmax_grow_max_trend'] = xr.DataArray(data   = tmp_tasmax_grow_max_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmax_grow_max_regrid.lat, 'lon':era5_tasmax_grow_max_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_tasmax_grow_max_trend.to_netcdf('era5/growing_season/era5_tasmax_grow_max_trend_%s.nc'%region)\n",
    "\n",
    "    era5_tasmax_grow_mean_trend['tasmax_grow_mean_trend'] = xr.DataArray(data   = tmp_tasmax_grow_mean_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmax_grow_mean_regrid.lat, 'lon':era5_tasmax_grow_mean_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_tasmax_grow_mean_trend.to_netcdf('era5/growing_season/era5_tasmax_grow_mean_trend_%s.nc'%region)\n",
    "    \n",
    "    era5_ef_grow_trend['ef_grow_trend'] = xr.DataArray(data   = tmp_ef_grow_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_ef_grow_regrid.lat, 'lon':era5_ef_grow_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_ef_grow_trend.to_netcdf('era5/growing_season/era5_ef_grow_trend_%s.nc'%region)\n",
    "else:\n",
    "    era5_tasmax_grow_max_trend = xr.open_dataset('era5/growing_season/era5_tasmax_grow_max_trend_%s.nc'%region)\n",
    "    era5_tasmax_grow_mean_trend = xr.open_dataset('era5/growing_season/era5_tasmax_grow_mean_trend_%s.nc'%region)    \n",
    "    era5_ef_grow_trend = xr.open_dataset('era5/growing_season/era5_ef_grow_trend_%s.nc'%region)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 ms, sys: 3.98 ms, total: 15.1 ms\n",
      "Wall time: 82.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# era5 trends over whole year\n",
    "\n",
    "recalc = False\n",
    "\n",
    "if recalc:\n",
    "    # calc era5 txx and t50p trends\n",
    "    era5_tasmax_max_trend = xr.Dataset()\n",
    "    era5_tasmax_monthly_max_trend = xr.Dataset()\n",
    "    era5_tasmax_mean_trend = xr.Dataset()\n",
    "\n",
    "    era5_tasmin_max_trend = xr.Dataset()\n",
    "    era5_tasmin_mean_trend = xr.Dataset()\n",
    "\n",
    "    print('calc era5 txx and t50p trends')\n",
    "    tmp_tasmax_max_trend = np.full([era5_tasmax_max_regrid.lat.values.shape[0], era5_tasmax_max_regrid.lon.values.shape[0]], np.nan)\n",
    "    tmp_tasmax_monthly_max_trend = np.full([12, era5_tasmax_max_regrid.lat.values.shape[0], era5_tasmax_max_regrid.lon.values.shape[0]], np.nan)\n",
    "    tmp_tasmax_mean_trend = np.full([era5_tasmax_mean_regrid.lat.values.shape[0], era5_tasmax_mean_regrid.lon.values.shape[0]], np.nan)\n",
    "\n",
    "    # tmp_tasmin_max_trend = np.full([era5_tasmin_max_regrid.lat.values.shape[0], era5_tasmin_max_regrid.lon.values.shape[0]], np.nan)\n",
    "    # tmp_tasmin_mean_trend = np.full([era5_tasmin_mean_regrid.lat.values.shape[0], era5_tasmin_mean_regrid.lon.values.shape[0]], np.nan)\n",
    "\n",
    "    monthly_groups = era5_tasmax_monthly_max_regrid.groupby('time.month').groups\n",
    "\n",
    "    for xlat in range(tmp_tasmax_max_trend.shape[0]):\n",
    "        for ylon in range(tmp_tasmax_max_trend.shape[1]):\n",
    "            cur_tasmax_max = era5_tasmax_max_regrid.tasmax_max.values[:, xlat, ylon]\n",
    "            X = sm.add_constant(range(1981, 2014+1))\n",
    "            mdl = sm.OLS(cur_tasmax_max, X).fit()\n",
    "            tmp_tasmax_max_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "            cur_tasmax_mean = era5_tasmax_mean_regrid.tasmax_mean.values[:, xlat, ylon]\n",
    "            X = sm.add_constant(range(1981, 2014+1))\n",
    "            mdl = sm.OLS(cur_tasmax_mean, X).fit()\n",
    "            tmp_tasmax_mean_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "    #         cur_tasmin_max = era5_tasmin_max_regrid.tasmin_max.values[:, xlat, ylon]\n",
    "    #         X = sm.add_constant(range(1981, 2014+1))\n",
    "    #         mdl = sm.OLS(cur_tasmin_max, X).fit()\n",
    "    #         tmp_tasmin_max_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "    #         cur_tasmin_mean = era5_tasmin_mean_regrid.tasmin_mean.values[:, xlat, ylon]\n",
    "    #         X = sm.add_constant(range(1981, 2014+1))\n",
    "    #         mdl = sm.OLS(cur_tasmin_mean, X).fit()\n",
    "    #         tmp_tasmin_mean_trend[xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "            for month in range(1, 13):\n",
    "                curMonthlyTx = era5_tasmax_monthly_max_regrid['tasmax_monthly_max'].values[monthly_groups[month], xlat, ylon]\n",
    "                X = sm.add_constant(range(1981, 2014+1))\n",
    "                mdl = sm.OLS(curMonthlyTx, X).fit()\n",
    "                tmp_tasmax_monthly_max_trend[month-1, xlat, ylon] = mdl.params[1]*10\n",
    "\n",
    "    era5_tasmax_max_trend['tasmax_max_trend'] = xr.DataArray(data   = tmp_tasmax_max_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmax_max_regrid.lat, 'lon':era5_tasmax_max_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_tasmax_max_trend.to_netcdf('era5/era5_tasmax_max_trend_%s.nc'%region)\n",
    "\n",
    "    era5_tasmax_monthly_max_trend['tasmax_monthly_max_trend'] = xr.DataArray(data   = tmp_tasmax_monthly_max_trend, \n",
    "                      dims   = ['month', 'lat', 'lon'],\n",
    "                      coords = {'month':np.arange(1,13), 'lat':era5_tasmax_monthly_max_regrid.lat, 'lon':era5_tasmax_monthly_max_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_tasmax_monthly_max_trend.to_netcdf('era5/era5_tasmax_monthly_max_trend_%s.nc'%region)\n",
    "\n",
    "    era5_tasmax_mean_trend['tasmax_mean_trend'] = xr.DataArray(data   = tmp_tasmax_mean_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmax_mean_regrid.lat, 'lon':era5_tasmax_mean_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "    era5_tasmax_mean_trend.to_netcdf('era5/era5_tasmax_mean_trend_%s.nc'%region)\n",
    "\n",
    "    era5_tasmin_max_trend['tasmin_max_trend'] = xr.DataArray(data   = tmp_tasmin_max_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmin_max_regrid.lat, 'lon':era5_tasmin_max_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "\n",
    "    era5_tasmin_mean_trend['tasmin_mean_trend'] = xr.DataArray(data   = tmp_tasmin_mean_trend, \n",
    "                      dims   = ['lat', 'lon'],\n",
    "                      coords = {'lat':era5_tasmin_mean_regrid.lat, 'lon':era5_tasmin_mean_regrid.lon},\n",
    "                      attrs  = {'units'     : 'C'\n",
    "                        })\n",
    "else:\n",
    "    era5_tasmax_max_trend = xr.open_dataset('era5/era5_tasmax_max_trend_%s.nc'%region)\n",
    "    era5_tasmax_monthly_max_trend = xr.open_dataset('era5/era5_tasmax_monthly_max_trend_%s.nc'%region)\n",
    "    era5_tasmax_mean_trend = xr.open_dataset('era5/era5_tasmax_mean_trend_%s.nc'%region)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasmax annual max\n",
      "tasmax monthly max\n",
      "month 0\n",
      "month 1\n",
      "month 2\n",
      "month 3\n",
      "month 4\n",
      "month 5\n",
      "month 6\n",
      "month 7\n",
      "month 8\n",
      "month 9\n",
      "month 10\n",
      "month 11\n",
      "tasmax growing season max\n",
      "tasmax growing season mean\n",
      "ef growing season mean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate trend bias between cmip6 and era5\n",
    "\n",
    "recalc = True\n",
    "\n",
    "if recalc:\n",
    "    # TASMAX ANNUAL MAX\n",
    "    print('tasmax annual max')\n",
    "    cmip6_era5_tasmax_max_trend_bias_sig = np.full(era5_tasmax_max_trend.tasmax_max_trend.shape, np.nan)\n",
    "    cmip6_era5_tasmax_max_trend_bias = np.full([len(cmip6_models), era5_tasmax_max_trend.tasmax_max_trend.shape[0], era5_tasmax_max_trend.tasmax_max_trend.shape[1]], np.nan)\n",
    "\n",
    "    for m, model in enumerate(cmip6_models):\n",
    "        cmip6_era5_tasmax_max_trend_bias[m,:,:] = cmip6_tasmax_max_trend.tasmax_max_trend.values[m,:,:] - era5_tasmax_max_trend.tasmax_max_trend.values\n",
    "\n",
    "    for xlat in range(cmip6_era5_tasmax_max_trend_bias_sig.shape[0]):\n",
    "        for ylon in range(cmip6_era5_tasmax_max_trend_bias_sig.shape[1]):\n",
    "            t, p = scipy.stats.ttest_1samp(cmip6_era5_tasmax_max_trend_bias[:, xlat, ylon], 0)\n",
    "            cmip6_era5_tasmax_max_trend_bias_sig[xlat, ylon] = p\n",
    "\n",
    "    # TASMAX MONTHLY MAX\n",
    "    print('tasmax monthly max')\n",
    "    cmip6_era5_tasmax_monthly_max_trend_bias_sig = np.full([12, era5_tasmax_monthly_max_trend.tasmax_monthly_max_trend.shape[1], era5_tasmax_monthly_max_trend.tasmax_monthly_max_trend.shape[2]], np.nan)\n",
    "    cmip6_era5_tasmax_monthly_max_trend_bias = np.full([12, len(cmip6_models), era5_tasmax_monthly_max_trend.tasmax_monthly_max_trend.shape[1], era5_tasmax_monthly_max_trend.tasmax_monthly_max_trend.shape[2]], np.nan)\n",
    "\n",
    "    for m, model in enumerate(cmip6_models):\n",
    "        for month in range(12):\n",
    "            cmip6_era5_tasmax_monthly_max_trend_bias[month,m,:,:] = cmip6_tasmax_monthly_max_trend.tasmax_monthly_max_trend.values[m,month,:,:] - era5_tasmax_monthly_max_trend.tasmax_monthly_max_trend.values[month,:,:]\n",
    "\n",
    "    for month in range(12):\n",
    "        print('month %d'%month)\n",
    "        for xlat in range(cmip6_era5_tasmax_monthly_max_trend_bias_sig.shape[1]):\n",
    "            for ylon in range(cmip6_era5_tasmax_monthly_max_trend_bias_sig.shape[2]):\n",
    "                t, p = scipy.stats.ttest_1samp(cmip6_era5_tasmax_monthly_max_trend_bias[month,:, xlat, ylon], 0)\n",
    "                cmip6_era5_tasmax_monthly_max_trend_bias_sig[month,xlat, ylon] = p\n",
    "\n",
    "\n",
    "    # TASMAX GROWING SEASON MAX\n",
    "    print('tasmax growing season max')\n",
    "    cmip6_era5_tasmax_grow_max_trend_bias_sig = np.full(era5_tasmax_grow_max_trend.tasmax_grow_max_trend.shape, np.nan)\n",
    "    cmip6_era5_tasmax_grow_max_trend_bias = np.full([cmip6_tasmax_grow_max_trend.model.size, era5_tasmax_grow_max_trend.tasmax_grow_max_trend.shape[0], era5_tasmax_grow_max_trend.tasmax_grow_max_trend.shape[1]], np.nan)\n",
    "\n",
    "    for m, model in enumerate(cmip6_tasmax_grow_max_trend.model):\n",
    "        cmip6_era5_tasmax_grow_max_trend_bias[m,:,:] = cmip6_tasmax_grow_max_trend.tasmax_grow_max_trend.values[m,:,:] - era5_tasmax_grow_max_trend.tasmax_grow_max_trend.values\n",
    "\n",
    "    for xlat in range(cmip6_era5_tasmax_grow_max_trend_bias_sig.shape[0]):\n",
    "        for ylon in range(cmip6_era5_tasmax_grow_max_trend_bias_sig.shape[1]):\n",
    "            t, p = scipy.stats.ttest_1samp(cmip6_era5_tasmax_grow_max_trend_bias[:, xlat, ylon], 0)\n",
    "            cmip6_era5_tasmax_grow_max_trend_bias_sig[xlat, ylon] = p\n",
    "\n",
    "    # TASMAX GROWING SEASON MEAN\n",
    "    print('tasmax growing season mean')\n",
    "    cmip6_era5_tasmax_grow_mean_trend_bias_sig = np.full(era5_tasmax_grow_mean_trend.tasmax_grow_mean_trend.shape, np.nan)\n",
    "    cmip6_era5_tasmax_grow_mean_trend_bias = np.full([cmip6_tasmax_grow_max_trend.model.size, era5_tasmax_grow_mean_trend.tasmax_grow_mean_trend.shape[0], era5_tasmax_grow_mean_trend.tasmax_grow_mean_trend.shape[1]], np.nan)\n",
    "\n",
    "    for m, model in enumerate(cmip6_tasmax_grow_max_trend.model):\n",
    "        cmip6_era5_tasmax_grow_mean_trend_bias[m,:,:] = cmip6_tasmax_grow_mean_trend.tasmax_grow_mean_trend.values[m,:,:] - era5_tasmax_grow_mean_trend.tasmax_grow_mean_trend.values\n",
    "\n",
    "    for xlat in range(cmip6_era5_tasmax_grow_mean_trend_bias_sig.shape[0]):\n",
    "        for ylon in range(cmip6_era5_tasmax_grow_mean_trend_bias_sig.shape[1]):\n",
    "            t, p = scipy.stats.ttest_1samp(cmip6_era5_tasmax_grow_mean_trend_bias[:, xlat, ylon], 0)\n",
    "            cmip6_era5_tasmax_grow_mean_trend_bias_sig[xlat, ylon] = p\n",
    "\n",
    "\n",
    "    # EF GROWING SEASON MEAN\n",
    "    print('ef growing season mean')\n",
    "    cmip6_era5_ef_grow_trend_bias_sig = np.full(era5_ef_grow_trend.ef_grow_trend.shape, np.nan)\n",
    "    cmip6_era5_ef_grow_trend_bias = np.full([cmip6_ef_grow_trend.model.size, era5_ef_grow_trend.ef_grow_trend.shape[0], era5_ef_grow_trend.ef_grow_trend.shape[1]], np.nan)\n",
    "\n",
    "    for m, model in enumerate(cmip6_ef_grow_trend.model):\n",
    "        cmip6_era5_ef_grow_trend_bias[m,:,:] = cmip6_ef_grow_trend.grow_ef.values[m,:,:] - era5_ef_grow_trend.ef_grow_trend.values\n",
    "\n",
    "    for xlat in range(cmip6_era5_ef_grow_trend_bias_sig.shape[0]):\n",
    "        for ylon in range(cmip6_era5_ef_grow_trend_bias_sig.shape[1]):\n",
    "            t, p = scipy.stats.ttest_1samp(cmip6_era5_ef_grow_trend_bias[:, xlat, ylon], 0)\n",
    "            cmip6_era5_ef_grow_trend_bias_sig[xlat, ylon] = p\n",
    "\n",
    "            \n",
    "    cmip6_era5_biases = {'cmip6_era5_tasmax_max_trend_bias':cmip6_era5_tasmax_max_trend_bias,\n",
    "                            'cmip6_era5_tasmax_max_trend_bias_sig':cmip6_era5_tasmax_max_trend_bias_sig,\n",
    "                        'cmip6_era5_tasmax_monthly_max_trend_bias':cmip6_era5_tasmax_monthly_max_trend_bias,\n",
    "                        'cmip6_era5_tasmax_monthly_max_trend_bias_sig':cmip6_era5_tasmax_monthly_max_trend_bias_sig,\n",
    "                         'cmip6_era5_tasmax_grow_max_trend_bias':cmip6_era5_tasmax_grow_max_trend_bias,\n",
    "                         'cmip6_era5_tasmax_grow_max_trend_bias_sig':cmip6_era5_tasmax_grow_max_trend_bias_sig,\n",
    "                         'cmip6_era5_tasmax_grow_mean_trend_bias':cmip6_era5_tasmax_grow_mean_trend_bias,\n",
    "                         'cmip6_era5_tasmax_grow_mean_trend_bias_sig':cmip6_era5_tasmax_grow_mean_trend_bias_sig,\n",
    "                         'cmip6_era5_ef_grow_trend_bias':cmip6_era5_ef_grow_trend_bias,\n",
    "                         'cmip6_era5_ef_grow_trend_bias_sig':cmip6_era5_ef_grow_trend_bias_sig}\n",
    "    \n",
    "    with open('cmip6_output/bias/cmip6-era5-bias.dat', 'wb') as f:\n",
    "        pickle.dump(cmip6_era5_biases, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yearly bias for access-cm2\n",
      "loading yearly bias for access-esm1-5\n",
      "loading yearly bias for awi-cm-1-1-mr\n",
      "loading yearly bias for bcc-csm2-mr\n",
      "loading yearly bias for bcc-esm1\n",
      "loading yearly bias for canesm5\n",
      "loading yearly bias for ec-earth3\n",
      "loading yearly bias for gfdl-cm4\n",
      "loading yearly bias for gfdl-esm4\n",
      "loading yearly bias for giss-e2-1-g\n",
      "loading yearly bias for kace-1-0-g\n",
      "loading yearly bias for fgoals-g3\n",
      "loading yearly bias for inm-cm5-0\n",
      "loading yearly bias for ipsl-cm6a-lr\n",
      "loading yearly bias for miroc6\n",
      "loading yearly bias for mpi-esm1-2-hr\n",
      "loading yearly bias for mpi-esm1-2-lr\n",
      "loading yearly bias for mri-esm2-0\n",
      "loading yearly bias for noresm2-lm\n",
      "loading yearly bias for noresm2-mm\n",
      "loading yearly bias for sam0-unicon\n"
     ]
    }
   ],
   "source": [
    "# load pre-calculated bias by year\n",
    "\n",
    "monthly_groups = cmip6_tasmax_monthly_max.groupby('time.month').groups\n",
    "\n",
    "yearly_tasmax_max_bias = np.full([len(cmip6_models), era5_tasmax_max_regrid.time.values.shape[0], \\\n",
    "                                  era5_tasmax_max_regrid.lat.values.shape[0], \\\n",
    "                                  era5_tasmax_max_regrid.lon.values.shape[0]], np.nan)\n",
    "yearly_tasmax_monthly_max_bias = np.full([len(cmip6_models), 12, len(monthly_groups[1]), \\\n",
    "                                  cmip6_tasmax_monthly_max.lat.values.shape[0], \\\n",
    "                                  cmip6_tasmax_monthly_max.lon.values.shape[0]], np.nan)\n",
    "yearly_tasmax_mean_bias = np.full([len(cmip6_models), era5_tasmax_mean_regrid.time.values.shape[0], \\\n",
    "                                   era5_tasmax_mean_regrid.lat.values.shape[0], \\\n",
    "                                   era5_tasmax_mean_regrid.lon.values.shape[0]], np.nan)\n",
    "\n",
    "yearly_tasmax_grow_max_bias = np.full([len(cmip6_models), era5_tasmax_grow_max_regrid.time.values.shape[0], \\\n",
    "                                  era5_tasmax_grow_max_regrid.lat.values.shape[0], \\\n",
    "                                  era5_tasmax_grow_max_regrid.lon.values.shape[0]], np.nan)\n",
    "yearly_tasmax_grow_mean_bias = np.full([len(cmip6_models), era5_tasmax_grow_mean_regrid.time.values.shape[0], \\\n",
    "                                   era5_tasmax_grow_mean_regrid.lat.values.shape[0], \\\n",
    "                                   era5_tasmax_grow_mean_regrid.lon.values.shape[0]], np.nan)\n",
    "yearly_ef_grow_bias = np.full([len(cmip6_models), era5_ef_grow_regrid.time.values.shape[0], \\\n",
    "                                   era5_ef_grow_regrid.lat.values.shape[0], \\\n",
    "                                   era5_ef_grow_regrid.lon.values.shape[0]], np.nan)\n",
    "\n",
    "for m, model in enumerate(cmip6_models):\n",
    "    print('loading yearly bias for %s'%model)\n",
    "    with open('cmip6_output/bias/yearly-cmip6-era5-tasmax-max-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "        yearly_tasmax_max_bias[m, :, :, :] = pickle.load(f)\n",
    "    with open('cmip6_output/bias/yearly-cmip6-era5-tasmax-monthly-max-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "        yearly_tasmax_monthly_max_bias[m, :, :, :, :] = pickle.load(f)\n",
    "    with open('cmip6_output/bias/yearly-cmip6-era5-tasmax-mean-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "        yearly_tasmax_mean_bias[m, :, :, :] = pickle.load(f)\n",
    "        \n",
    "    with open('cmip6_output/bias/yearly-cmip6-era5-tasmax-grow-max-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "        yearly_tasmax_grow_max_bias[m, :, :, :] = pickle.load(f)\n",
    "    with open('cmip6_output/bias/yearly-cmip6-era5-tasmax-grow-mean-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "        yearly_tasmax_grow_mean_bias[m, :, :, :] = pickle.load(f)\n",
    "    if os.path.isfile('cmip6_output/bias/yearly-cmip6-era5-ef-grow-bias-%s-%s.dat'%(region, model)):\n",
    "        with open('cmip6_output/bias/yearly-cmip6-era5-ef-grow-bias-%s-%s.dat'%(region, model), 'rb') as f:\n",
    "            yearly_ef_grow_bias[m, :, :, :] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load deepak data\n",
    "\n",
    "recalc = False\n",
    "\n",
    "if not os.path.isfile('deepak_regions/deepak_maize_%s.nc'%region) or recalc:\n",
    "    \n",
    "    maize_yield_deepak_ds = xr.Dataset()\n",
    "    soy_yield_deepak_ds = xr.Dataset()\n",
    "    wheat_yield_deepak_ds = xr.Dataset()\n",
    "\n",
    "    for y, year in enumerate(range(1979, 2013+1)):\n",
    "        print('processing deepak for %d...'%year)\n",
    "        cur_maize_yield_deepak_ds = xr.open_dataset('%s/Maize_yield_1970_2013/Maize_areaweightedyield_%d_ver12b.nc'%(dirDeepak, year))\n",
    "\n",
    "        lonvals = cur_maize_yield_deepak_ds['longitude'].values\n",
    "        lonvals[lonvals < 0] = 360+lonvals[lonvals < 0]\n",
    "        cur_maize_yield_deepak_ds['longitude'] = lonvals\n",
    "\n",
    "        latvals = cur_maize_yield_deepak_ds['latitude'].values\n",
    "        cur_maize_yield_deepak_ds['latitude'] = latvals\n",
    "\n",
    "        cur_maize_yield_deepak_ds = cur_maize_yield_deepak_ds.rename(latitude='lat', longitude='lon')\n",
    "\n",
    "        cur_maize_yield_deepak_ds.load()\n",
    "\n",
    "        regridder = xe.Regridder(cur_maize_yield_deepak_ds, regridMesh, 'bilinear')\n",
    "        regridder.clean_weight_file()\n",
    "        cur_maize_yield_deepak_ds_regrid = regridder(cur_maize_yield_deepak_ds.Data)\n",
    "\n",
    "        tempDs_maize_yield = xr.Dataset()\n",
    "        tempDs_maize_yield['maize_yield'] = xr.DataArray(data = np.squeeze(cur_maize_yield_deepak_ds_regrid.values, axis=1), \n",
    "                              dims   = ['time', 'lat', 'lon'],\n",
    "                              coords = {'time':[datetime.datetime(year,1,1)], 'lat':regridMesh['lat'], 'lon':regridMesh['lon']},\n",
    "                              attrs  = {'units'     : 't/ha'\n",
    "                                })\n",
    "\n",
    "        if y == 0:\n",
    "            maize_yield_deepak_ds = tempDs_maize_yield\n",
    "        else:\n",
    "            maize_yield_deepak_ds = xr.concat([maize_yield_deepak_ds, tempDs_maize_yield], dim='time')\n",
    "        \n",
    "        \n",
    "        \n",
    "        cur_soy_yield_deepak_ds = xr.open_dataset('%s/Soy_yield_1970_2013/Soybean_areaweightedyield_%d_ver12b.nc'%(dirDeepak, year))\n",
    "\n",
    "        lonvals = cur_soy_yield_deepak_ds['longitude'].values\n",
    "        lonvals[lonvals < 0] = 360+lonvals[lonvals < 0]\n",
    "        cur_soy_yield_deepak_ds['longitude'] = lonvals\n",
    "\n",
    "        latvals = cur_soy_yield_deepak_ds['latitude'].values\n",
    "        cur_soy_yield_deepak_ds['latitude'] = latvals\n",
    "\n",
    "        cur_soy_yield_deepak_ds = cur_soy_yield_deepak_ds.rename(latitude='lat', longitude='lon')\n",
    "\n",
    "        cur_soy_yield_deepak_ds.load()\n",
    "\n",
    "        regridder = xe.Regridder(cur_soy_yield_deepak_ds, regridMesh, 'bilinear')\n",
    "        regridder.clean_weight_file()\n",
    "        cur_soy_yield_deepak_ds_regrid = regridder(cur_soy_yield_deepak_ds.Data)\n",
    "\n",
    "        tempDs_soy_yield = xr.Dataset()\n",
    "        tempDs_soy_yield['soy_yield'] = xr.DataArray(data = np.squeeze(cur_soy_yield_deepak_ds_regrid.values, axis=1), \n",
    "                              dims   = ['time', 'lat', 'lon'],\n",
    "                              coords = {'time':[datetime.datetime(year,1,1)], 'lat':regridMesh['lat'], 'lon':regridMesh['lon']},\n",
    "                              attrs  = {'units'     : 't/ha'\n",
    "                                })\n",
    "\n",
    "        if y == 0:\n",
    "            soy_yield_deepak_ds = tempDs_soy_yield\n",
    "        else:\n",
    "            soy_yield_deepak_ds = xr.concat([soy_yield_deepak_ds, tempDs_soy_yield], dim='time')\n",
    "        \n",
    "        \n",
    "        \n",
    "        cur_wheat_yield_deepak_ds = xr.open_dataset('%s/Wheat_yield_1970_2013/Wheat_areaweightedyield_%d_ver12b.nc'%(dirDeepak, year))\n",
    "\n",
    "        lonvals = cur_wheat_yield_deepak_ds['longitude'].values\n",
    "        lonvals[lonvals < 0] = 360+lonvals[lonvals < 0]\n",
    "        cur_wheat_yield_deepak_ds['longitude'] = lonvals\n",
    "\n",
    "        latvals = cur_wheat_yield_deepak_ds['latitude'].values\n",
    "        cur_wheat_yield_deepak_ds['latitude'] = latvals\n",
    "\n",
    "        cur_wheat_yield_deepak_ds = cur_wheat_yield_deepak_ds.rename(latitude='lat', longitude='lon')\n",
    "\n",
    "        cur_wheat_yield_deepak_ds.load()\n",
    "\n",
    "        regridder = xe.Regridder(cur_wheat_yield_deepak_ds, regridMesh, 'bilinear')\n",
    "        regridder.clean_weight_file()\n",
    "        cur_wheat_yield_deepak_ds_regrid = regridder(cur_wheat_yield_deepak_ds.Data)\n",
    "\n",
    "        tempDs_wheat_yield = xr.Dataset()\n",
    "        tempDs_wheat_yield['wheat_yield'] = xr.DataArray(data = np.squeeze(cur_wheat_yield_deepak_ds_regrid.values, axis=1), \n",
    "                              dims   = ['time', 'lat', 'lon'],\n",
    "                              coords = {'time':[datetime.datetime(year,1,1)], 'lat':regridMesh['lat'], 'lon':regridMesh['lon']},\n",
    "                              attrs  = {'units'     : 't/ha'\n",
    "                                })\n",
    "\n",
    "        if y == 0:\n",
    "            wheat_yield_deepak_ds = tempDs_wheat_yield\n",
    "        else:\n",
    "            wheat_yield_deepak_ds = xr.concat([wheat_yield_deepak_ds, tempDs_wheat_yield], dim='time')\n",
    "            \n",
    "    maize_yield_deepak_ds.to_netcdf('deepak_regions/deepak_maize_%s.nc'%region)\n",
    "    soy_yield_deepak_ds.to_netcdf('deepak_regions/deepak_soy_%s.nc'%region)\n",
    "    wheat_yield_deepak_ds.to_netcdf('deepak_regions/deepak_wheat_%s.nc'%region)\n",
    "else:\n",
    "    maize_yield_deepak_ds = xr.open_dataset('deepak_regions/deepak_maize_%s.nc'%region)\n",
    "    soy_yield_deepak_ds = xr.open_dataset('deepak_regions/deepak_soy_%s.nc'%region)\n",
    "    wheat_yield_deepak_ds = xr.open_dataset('deepak_regions/deepak_wheat_%s.nc'%region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecoffel",
   "language": "python",
   "name": "ecoffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
